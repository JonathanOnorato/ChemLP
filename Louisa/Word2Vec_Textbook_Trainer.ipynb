{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string \n",
    "import pandas as pd \n",
    "from time import time  \n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    #removes unicodes left in text so model does not learn unicodes\n",
    "    text = re.sub('^\\\\\\\\u[\\d\\D]{4}|-|σ|→|\\\\\\\\xad', '', text)\n",
    "    # Remove a sentence if it is only one word long\n",
    "    if len(text) > 2:\n",
    "        return ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatizer(text):\n",
    "    if text == None:\n",
    "        print(\"Daisy, daisy, sour cream!!!\")\n",
    "        return \"\"\n",
    "    sent = []\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#types = df_clean.apply(lambda x: type(x['text']), axis=1)\n",
    "\n",
    "df = pd.read_json('ChemLibre_JSONS/Basic_Principles_of_Organic_Chemistry_Roberts_and_Caserio.json')\n",
    "df.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(df.text.apply(lambda x: clean_text(x)))\n",
    "#filters out all the None values in the cleaned dataset\n",
    "#loc combines the operations in brackets into one single operation to avoid chaining indexes operations together\n",
    "#copy explicitly tells pandas to make copy when creating master_of_none\n",
    "#this is so later on only the copy is modified and there is no confusion between the copy and the original\n",
    "master_of_none = df_clean.loc[df_clean.text.notnull()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_of_none[\"text_lemmatized\"] =  master_of_none.apply(lambda x: lemmatizer(x['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['text_lemmatize_clean'] = df_clean['text_lemmatize'].str.replace('-PRON-', '')\n",
    "master_of_none['text_lemmatize_clean'] = master_of_none['text_lemmatized'].str.replace('-PRON-', '')\n",
    "\n",
    "sentences = [row.split() for row in master_of_none['text_lemmatize_clean']]\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    #tokens = tokenizer(sent)\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)\n",
    "\n",
    "# min_count: minimum number of occurrences of a word in the corpus to be included in the model.\n",
    "# window: the maximum distance between the current and predicted word within a sentence.\n",
    "# size: the dimensionality of the feature vectors\n",
    "# workers: I know my system is having 4 cores,\n",
    "\n",
    "w2v_model = Word2Vec(min_count=50,\n",
    "                     window=5,\n",
    "                     size=400,\n",
    "                     workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c',\n",
       " 'ch',\n",
       " 'reaction',\n",
       " 'h',\n",
       " 'acid',\n",
       " 'bond',\n",
       " '−',\n",
       " 'compound',\n",
       " 'group',\n",
       " 'exercise']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line of code to prepare the model vocabulary\n",
    "w2v_model.build_vocab(sentences)\n",
    "#w2v_model.build_vocab(sentences, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486403, 855525)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train word vectors\n",
    "#returns the number of words in the vocab and the number of words in the corpus\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chapter', 0.9960504770278931),\n",
       " ('many', 0.9957904815673828),\n",
       " ('organic', 0.9949187636375427),\n",
       " ('discuss', 0.994277834892273),\n",
       " ('important', 0.9889111518859863),\n",
       " ('material', 0.9760055541992188),\n",
       " ('property', 0.9737546443939209),\n",
       " ('start', 0.9723126888275146),\n",
       " ('shall', 0.9699676632881165),\n",
       " ('detail', 0.964913547039032)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the model\n",
    "w2v_model.wv.most_similar(positive=['chemistry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523978"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('alcohol', 'hydroxyl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('ketone', 'carbonyl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('alkene', 'alkyne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8551333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('acid', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833495"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('oxidize', 'reduce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98936796"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('anion', 'cation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06520185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('mechanism', 'atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18401119"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('resonance', 'solvent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07550056"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('synthesis', 'electron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"testing.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we do not plan to train the model any further, \n",
    "# we are calling init_sims(), which will make the model much more memory-efficient\n",
    "#w2v_model.init_sims(replace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
