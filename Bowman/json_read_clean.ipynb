{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes in a local json filename and reads it into a single list. It also removes punctuation and null values.\n",
    "It has default punctuation it keeps \"(, ), -, \", but this can be added to.\"\"\" \n",
    "\n",
    "#TO-DO:\n",
    "#remove string if only numbers\n",
    "#document this better, add doc_strings to methods and overall just make better \n",
    "\n",
    "\n",
    "import Ruk_Reader\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "\n",
    "def json_cleaner(local_book_title, extra_strings_to_keep = \"\", print_state = True ):\n",
    "    \n",
    "    #this method removes the noise from array\n",
    "    def _remove_noise(input_text, noise_list):\n",
    "        if isinstance(input_text, list):\n",
    "            for word in input_text:\n",
    "                letters = list(word)\n",
    "                for letter in letters:\n",
    "                    if letter in noise_list:\n",
    "                        letters.remove(letter)\n",
    "                word = \"\".join(letters)\n",
    "                noise_free_words.append(word) \n",
    "            return noise_free_words.split()\n",
    "    \n",
    "        elif isinstance(input_text, str):\n",
    "            letters = list(input_text)\n",
    "            for letter in letters:\n",
    "                if letter in noise_list:\n",
    "                    letters.remove(letter)\n",
    "            noise_free_word = \"\".join(letters)\n",
    "            return noise_free_word\n",
    "    \n",
    "\n",
    "#Deciding the noise/punctuation to remove from input list\n",
    "    initial_noise = [\"''\"] \n",
    "    updated_punct = ''.join(i for i in string.punctuation if not i in ['(', ')', '-']) #+ extra_strings_to_keep\n",
    "    for i in range (0, len(updated_punct)):\n",
    "        initial_noise.append(updated_punct[i])\n",
    "    if extra_strings_to_keep:\n",
    "        initial_noise.remove(extra_strings_to_keep)\n",
    "        \n",
    "    \n",
    "#instantiating lists\n",
    "    all_words = []\n",
    "    stripped = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#reading file\n",
    "    with open(local_book_title, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    \n",
    "    print(\"data is \", type(data))\n",
    "\n",
    "#looks at keys of dictionary that is the data read. The main content is in the \"chap-content\"\n",
    "    print(type(data))\n",
    "    if isinstance(data, dict):\n",
    "        subchap_headings = data.keys()\n",
    "        print(\"dictionary keys: \", subchap_headings)  #these are probably removable\n",
    "        print()\n",
    "        all_content = data.get(\"chap-content\") \n",
    "    elif isinstance(data, str):\n",
    "        all_content = data.split()\n",
    "    elif isinstance(data, list):\n",
    "        all_content = data\n",
    "\n",
    "#Turns list of lists into single list, also removes stopwords, and makes lowercase\n",
    "\n",
    "    for i in range(0, len(all_content)):\n",
    "        if all_content[i]:\n",
    "            all_content[i] = _remove_noise(all_content[i], initial_noise)\n",
    "            all_content[i] = all_content[i].split()\n",
    "            for j in range(0, len(all_content[i])):\n",
    "                if all_content[i][j] and \"http\" not in all_content[i][j] and all_content[i][j] not in stop_words and all_content[i][j].isdigit() == False:\n",
    "                    all_words.append(all_content[i][j].lower())\n",
    "    \n",
    "    if print_state:\n",
    "        print(all_words)\n",
    "    \n",
    "    else:\n",
    "        return all_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_cleaner(r\"C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:13:55: 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This function takes in a bunch of things and creates a word2vec CBOW NN\"\"\"\n",
    "\n",
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import spacy  # For preprocessing\n",
    "from spacy.lang.en import English  #not sure what this is for, check if needed\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser  #for bigrams/common phrase ID\n",
    "\n",
    "\n",
    "\n",
    "def word2vec_book_model(list_of_book_words, min_count=2, window = 2, size = 300, sample = 6e-5, alpha=0.03\n",
    "                       ,min_alpha = 0.0007, negative = 0, workers = 6):\n",
    "\n",
    "    phrases = Phrases(list_of_book_words, min_count=30, progress_per=10000)   \n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = bigram[list_of_book_words]\n",
    "    \n",
    "    cores = multiprocessing.cpu_count() \n",
    "\n",
    "#1) INITALIZING THE MODEL\n",
    "    w2v_model = Word2Vec(min_count = min_count,         #Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "                     window = window,           #The maximum distance between the current and predicted word within a sentence.\n",
    "                     size = size,           #size of feature vectors\n",
    "                     sample = sample,   #threshold for configuring which higher-frequency words are randomly downsampled. influencial. (0, 1e-5)\n",
    "                     alpha = alpha,        #learning rate initial (0.01 - 0.05)\n",
    "                     min_alpha = min_alpha,     #final learning rate, linearly drops to this as training goes\n",
    "                     negative = negative,  # If > 0,  how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "                     workers = workers)        #how many cores doing the work\n",
    "\n",
    "#2) BUILDING VOCAB\n",
    "    t = time()\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    \n",
    "#3) TRAINING MODEL\n",
    "\n",
    "    #    total_examples = int, Count of sentences;\n",
    "    #   epochs = int - Number of iterations (epochs) over the corpus - [10, 20, 30]\n",
    "    \n",
    "    t = time()\n",
    "    print(\"length of total examples is \", len(sentences))\n",
    "    w2v_model.train(sentences, total_examples = len(sentences), epochs=30, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "\n",
    "    w2v_model.init_sims(replace=True)  #do this when done training the model? normalizes the length of the vectors before comparing\n",
    "    \n",
    "    print(\"the size of the vocabulary is: \", len(w2v_model.wv.vocab))\n",
    "    print(\"size of the corpus_count:\", w2v_model.corpus_count)  #\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn this to a function that can be used to create a super list for full pckg for word2vec .py file\n",
    "\n",
    "def bow_list_maker():   #add default string to take in for additional characters to keep\n",
    "    \"\"\"This function is similar to super list maker, and the feed2vec function, but instead of creating a dataframe, the function creates a \n",
    "    list of lists, where each list is all the cleaned words from a book. It calls json_cleaner defined above\"\"\"\n",
    "    \n",
    "    initPath = input(\"Enter a file location\")\n",
    "    bookType = input(\"Enter a data type(.json please)\")\n",
    "    token_list = []\n",
    "    final_list = []\n",
    "    if bookType:\n",
    "        path = initPath + \"\\*\" + bookType\n",
    "    else:\n",
    "        path = initPath\n",
    "    raw_path = r\"{}\".format(path)\n",
    "    bookList = glob.glob(raw_path)\n",
    "    \n",
    "    yesOrNo = input(\"Is there an additional file type? (y or n) \")\n",
    "    if yesOrNo == \"y\":\n",
    "        bookType2 = input(\"Enter a second data type(.txt) \")\n",
    "        path2 = initPath + \"\\*\" + bookType2\n",
    "        raw_path2 = r\"{}\".format(path2)\n",
    "        bookList2 = glob.glob(raw_path2)\n",
    "        for bookSite in bookList2:\n",
    "            bookList.append(bookSite)\n",
    "            \n",
    "    print(\"book list is \", bookList)\n",
    "    Multiple_book_list = []\n",
    "    #local_titles = [\"Principles_of_Polymer_Chemistry_by_Ravve.json\", \"Schaller_polym_chem\", \"Soderberg_bio_o_chem\"]\n",
    "    \n",
    "    for title in bookList:\n",
    "        list_of_words = json_cleaner(title, \"\", False)\n",
    "        Multiple_book_list.append(list_of_words)\n",
    "        print(len(Multiple_book_list))\n",
    "        print(\"length of \", title, \"is \", len(list_of_words))\n",
    "    \n",
    "    for book in Multiple_book_list:\n",
    "        print(len(book))\n",
    "        print(book[:100])\n",
    "        \n",
    "    return Multiple_book_list\n",
    "\n",
    "    #\"C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a file location C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\n",
      "Enter a data type(.json please) .json\n",
      "Is there an additional file type? (y or n)  y\n",
      "Enter a second data type(.txt)  .txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book list is  ['C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Polymer_Chemistry_by_Koltzsenburg_Maskos_and_Nuyken.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Polymer_Synthesis_Theory_and_Practice_by_Braun_Cherdron_Rehahn_Ritter_and_Voit.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Basic Principles of Organic Chemistry (Roberts and Caserio).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Logic of Organic Synthesis (Rao).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Organic Chemistry - A Carbonyl Early Approach (McMichael).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Soderberg_bio_o_chem.txt']\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "1\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json is  82618\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "2\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Polymer_Chemistry_by_Koltzsenburg_Maskos_and_Nuyken.json is  107303\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "3\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Polymer_Synthesis_Theory_and_Practice_by_Braun_Cherdron_Rehahn_Ritter_and_Voit.json is  96937\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "4\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Basic Principles of Organic Chemistry (Roberts and Caserio).txt is  193988\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "5\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Logic of Organic Synthesis (Rao).txt is  13431\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "6\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Organic Chemistry - A Carbonyl Early Approach (McMichael).txt is  29024\n",
      "data is  <class 'list'>\n",
      "<class 'list'>\n",
      "7\n",
      "length of  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Soderberg_bio_o_chem.txt is  91495\n",
      "82618\n",
      "['michael', 'mosher', '·', 'kenneth', 'trantham', 'brewing', 'science', 'multidisciplinary', 'approach', 'brewing', 'science', 'multidisciplinary', 'approach', 'michael', 'mosher', '•', 'kenneth', 'trantham', 'brewing', 'science', 'multidisciplinary', 'approach', 'michael', 'mosher', 'department', 'chemistry', 'biochemistry', 'university', 'northern', 'colorado', 'greeley', 'co', 'usa', 'kenneth', 'trantham', 'department', 'physics', 'physical', 'science', 'university', 'nebraska', 'kearney', 'kearney', 'ne', 'usa', 'isbn', '978-3-319-46393-3', 'doi', '101007978-3-319-46394-0', 'isbn', '978-3-319-46394-0', '(ebook)', 'library', 'congress', 'control', 'number', '©', 'springer', 'international', 'publishing', 'switzerland', 'work', 'subject', 'copyright', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'material', 'concerned', 'specifically', 'rights', 'translation', 'reprinting', 'reuse', 'illustrations', 'recitation', 'broadcasting', 'reproduction', 'microfilms', 'physical', 'way', 'transmission', 'information', 'storage', 'retrieval', 'electronic', 'adaptation', 'computer', 'software', 'similar', 'dissimilar', 'methodology', 'known', 'hereafter', 'developed', 'use', 'general']\n",
      "107303\n",
      "['sebastian', 'koltzenburg', 'michael', 'maskos', 'oskar', 'nuyken', 'polymer', 'chemistry', 'polymer', 'chemistry', 'sebastian', 'koltzenburg', 'michael', 'maskos', 'oskar', 'nuyken', 'polymer', 'chemistry', 'sebastian', 'koltzenburg', 'functional', 'biopolymers', 'basf', 'se', 'gmmb', '-', 'b001', 'ludwigshafen', 'germany', 'michael', 'maskos', 'fraunhofer', 'ict-imm', 'mainz', 'germany', 'oskar', 'nuyken', 'garching', 'germany', 'translated', 'karl', 'hughes', 'forewords', 'rolf', 'mulhaupt', 'krzysztof', 'matyjaszewski', 'isbn', '978-3-662-49277-2', 'doi', '101007978-3-662-49279-6', 'isbn', '978-3-662-49279-6', '(ebook)', 'library', 'congress', 'control', 'number', '©', 'springer-verlag', 'berlin', 'heidelberg', 'work', 'subject', 'copyright', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'material', 'concerned', 'specifically', 'rights', 'translation', 'reprinting', 'reuse', 'illustrations', 'recitation', 'broadcasting', 'reproduction', 'microfilms', 'physical', 'way', 'transmission', 'information', 'storage', 'retrieval', 'electronic', 'adaptation', 'computer', 'software', 'similar', 'dissimilar', 'methodology', 'known', 'hereafter', 'developed', 'use']\n",
      "96937\n",
      "['polymer', 'synthesis', 'theory', 'practice', 'dietrich', 'braun', '(29)', 'harald', 'cherdron', 'matthias', 'rehahn', '(29)', 'helmut', 'ritter', 'brigitte', 'voit', 'polymer', 'synthesis', 'theory', 'practice', 'fundamentals', 'methods', 'experiments', 'fifth', 'edition', 'dietrich', 'braun', 'technische', 'universitat', 'darmstadt', 'darmstadt', 'germany', 'harald', 'cherdron', 'wiesbaden', 'germany', 'helmut', 'ritter', 'heinrich-heine-universitat', 'd€usseldorf', 'institut', 'f€ur', 'organische', 'chemie', 'und', 'makromolekulare', 'chemie', 'd€usseldorf', 'germany', 'matthias', 'rehahn', 'technische', 'universitat', 'darmstadt', 'ernst-berl-institut', 'f€ur', 'technische', 'und', 'makromolekulare', 'chemie', 'fg', 'der', 'polymeren', 'darmstadt', 'germany', 'brigitte', 'voit', 'leibniz-institut', 'fu¨r', 'polymerforschung', 'dresden', 'ev', 'dresden', 'germany', 'isbn', '978-3-642-28979-8', 'doi', '101007978-3-642-28980-4', 'springer', 'heidelberg', 'new', 'york', 'dordrecht', 'london', 'isbn', '978-3-642-28980-4', '(ebook)', 'library', 'congress', 'control', 'number', 'springer-verlag', 'berlin', 'heidelberg', 'work', 'subject', 'copyright', 'rights', 'reserved', 'publisher']\n",
      "193988\n",
      "['introduction', 'organic', 'chemistry', 'you', 'starting', 'study', 'organic', 'chemistry', 'chemistry', 'compounds', 'carbon', 'in', 'introductory', 'chapter', 'tell', 'some-', 'thing', 'background', 'history', 'organic', 'chemistry', 'something', 'problems', 'rewards', 'involved', 'something', 'philosophy', 'important', 'learn', 'reasonable', 'working', 'knowledge', 'subject', 'whether', 'interested', 'chemistry', 'plan', 'career', 'chemist', 'structural', 'organic', 'chemistry', 'this', 'chapter', 'briefly', 'reviews', 'important', 'types', 'covalent', 'bonds', 'encountered', 'organic', 'substances', 'ways', 'bonds', 'represented', 'structural', 'formulas', 'then', 'considers', 'sizes', 'shapes', 'organic', 'molecules', 'structural', 'formulas', 'written', 'two', 'dimensions', 'translated', 'three-dimensional', 'models', 'show', 'relative', 'positions', 'atoms', 'space', 'we', 'also', 'discuss', 'models', 'reflect', 'relative', 'sizes', 'atoms', 'may', 'sterically', 'interact', 'organic', 'nomenclature', 'a', 'chemical', 'nomenclature', 'set', 'rules', 'generate', 'systematic', 'names', 'chemical', 'compounds']\n",
      "13431\n",
      "['synthesis', 'organic', 'molecules', 'rules', 'guidelines', 'governing', 'organic', 'synthesis', 'baldwin’s', 'rule', 'ring', 'closure', 'reactions', 'bredts', 'rule', 'crams', 'rule', 'prelogs', 'rule', 'hofmann’s', 'rule', 'zaitsev’s', 'rule', 'markovnikov', 'rule', 'criteria', 'selection', 'synthetic', 'route', 'the', 'logic', 'synthesis', 'strategies', 'disparlure', 'synthesis', 'strategies', '(-)-menthol', 'synthesis', 'strategies', 'longfolene', 'synthesis', 'strategies', 'cedrene', 'synthesis', 'strategies', 'reserpine', 'synthesis', 'strategies', 'prostaglandins', 'synthesis', 'strategies', 'steroids', 'synthesis', 'woodward’s', 'synthesis', 'chlorophyll', 'synthesis', 'vitamin', 'b₁₂', 'green', 'chemistry', '-', 'protection-free', 'organic', 'synthesis', 'baldwin’s', 'rule', 'ring', 'closure', 'reactions', 'bredts', 'rule', 'crams', 'rule', 'prelogs', 'rule', 'hofmann’s', 'rule', 'zaitsev’s', 'rule', 'markovnikov', 'rule', 'wöhler', 'synthesis', 'urea', 'heralded', 'birth', 'modern', 'chemistry', 'the', 'art', 'synthesis', 'old', 'organic', 'chemistry', 'natural', 'product', 'chemistry', 'firmly', 'rooted']\n",
      "29024\n",
      "['carbonyl', 'group', 'notation', 'structure', 'bonding', 'functional', 'groups', 'hybridization', 'naming', 'additions', 'electrophilic', 'nucleophilic', 'acetal', 'formation', 'mechanism', 'resonance', 'nitrogen', 'nucleophiles', '-', 'imine', 'formation', 'addition', 'organometallics', '-', 'grignard', 'oxidation', 'reduction', 'alpha-c-h', 'acidity', 'enolates', 'aldol', 'condensation', 'synthesis', 'carboxylic', 'acid', 'derivatives', 'interconversion', 'carboxylic', 'acid', 'derivatives', '-', 'alpha', 'carbon', 'reactions', 'fats', 'fatty', 'acids', 'detergents', 'carboxylic', 'acids', 'alcohols', 'ethers', 'epoxides', 'thiols', 'chirality', 'three', 'dimensional', 'structure', 'rs', 'naming', 'two', 'more', 'stereogenic', 'centers', 'carbohydrates', 'monosaccharides', 'glycosides', 'disaccharides', 'polysaccharides', 'amines', 'structure', 'synthesis', 'amines', 'reactions', 'amino', 'acids', 'peptides', 'proteins', 'nucleic', 'acids', 'nucleophilic', 'substitution', 'sn2', 'sn1', 'elimination', '-', 'e2', 'e1', 'alkenes', 'alkyne', 'structure', 'electrophilic', 'additions', 'polymers', 'metabolic', 'organic', 'reactions', 'aromatic', 'compounds', 'electrophilic']\n",
      "91495\n",
      "['introduction', 'organic', 'structure', 'bonding', 'i', 'in', 'chapter', 'introduced', 'fundamental', 'principles', 'organic', 'chemistry', 'you', 'recognize', 'chapter', 'contains', 'lot', 'review', 'topics', 'probably', 'learned', 'already', 'introductory', 'chemistry', 'course', 'likely', 'also', 'concepts', 'new', 'well', 'topics', 'already', 'familiar', 'covered', 'greater', 'depth', 'emphasis', 'biologically', 'relevant', 'organic', 'compounds', 'introduction', 'organic', 'structure', 'bonding', 'ii', 'conformations', 'stereochemistry', 'structure', 'determination', 'i-', 'uv-vis', 'infrared', 'spectroscopy', 'mass', 'spectrometry', 'spectroscopy', 'use', 'absorption', 'emission', 'scattering', 'electromagnetic', 'radiation', 'atoms', 'molecules', '(or', 'atomic', 'molecular', 'ions)', 'qualitatively', 'quantitatively', 'study', 'atoms', 'molecules', 'study', 'physical', 'processes', 'the', 'interaction', 'radiation', 'matter', 'cause', 'redirection', 'radiation', 'andor', 'transitions', 'energy', 'levels', 'atoms', 'molecules', 'structure', 'determination', 'part', 'ii', '-', 'nuclear', 'magnetic', 'resonance', 'spectroscopy', 'in']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:14:09: collecting all words and their counts\n",
      "INFO - 10:14:09: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 10:14:10: collected 441496 word types from a corpus of 614796 words (unigram + bigrams) and 7 sentences\n",
      "INFO - 10:14:10: using 441496 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 10:14:10: source_vocab length 441496\n",
      "INFO - 10:14:14: Phraser built with 452 phrasegrams\n",
      "INFO - 10:14:14: collecting all words and their counts\n",
      "INFO - 10:14:14: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 10:14:15: collected 46980 word types from a corpus of 581252 raw words and 7 sentences\n",
      "INFO - 10:14:15: Loading a fresh vocabulary\n",
      "INFO - 10:14:15: effective_min_count=10 retains 6851 unique words (14% of original 46980, drops 40129)\n",
      "INFO - 10:14:15: effective_min_count=10 leaves 501142 word corpus (86% of original 581252, drops 80110)\n",
      "INFO - 10:14:15: deleting the raw counts dictionary of 46980 items\n",
      "INFO - 10:14:15: sample=6e-05 downsamples 1448 most-common words\n",
      "INFO - 10:14:15: downsampling leaves estimated 304908 word corpus (60.8% of prior 501142)\n",
      "INFO - 10:14:15: estimated required memory for 6851 words and 400 dimensions: 25348700 bytes\n",
      "INFO - 10:14:15: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n",
      "length of total examples is  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:14:15: training model with 6 workers on 6851 vocabulary and 400 features, using sg=0 hs=0 sample=6e-05 negative=10 window=4\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:16: EPOCH 1 - PROGRESS: at 85.71% examples, 49403 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:16: EPOCH - 1 : training on 581252 raw words (66610 effective words) took 1.2s, 57384 effective words/s\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:17: EPOCH 2 - PROGRESS: at 85.71% examples, 48844 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:17: EPOCH - 2 : training on 581252 raw words (66574 effective words) took 1.2s, 56552 effective words/s\n",
      "INFO - 10:14:18: EPOCH 3 - PROGRESS: at 71.43% examples, 44886 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:18: EPOCH - 3 : training on 581252 raw words (66618 effective words) took 1.2s, 55225 effective words/s\n",
      "INFO - 10:14:19: EPOCH 4 - PROGRESS: at 71.43% examples, 46017 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:20: EPOCH - 4 : training on 581252 raw words (66520 effective words) took 1.2s, 55318 effective words/s\n",
      "INFO - 10:14:21: EPOCH 5 - PROGRESS: at 71.43% examples, 46391 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:21: EPOCH - 5 : training on 581252 raw words (66598 effective words) took 1.2s, 55529 effective words/s\n",
      "INFO - 10:14:22: EPOCH 6 - PROGRESS: at 71.43% examples, 45818 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:22: EPOCH - 6 : training on 581252 raw words (66625 effective words) took 1.2s, 55583 effective words/s\n",
      "INFO - 10:14:23: EPOCH 7 - PROGRESS: at 71.43% examples, 45698 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:23: EPOCH - 7 : training on 581252 raw words (66556 effective words) took 1.2s, 55234 effective words/s\n",
      "INFO - 10:14:24: EPOCH 8 - PROGRESS: at 57.14% examples, 39450 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:25: EPOCH - 8 : training on 581252 raw words (66625 effective words) took 1.2s, 54509 effective words/s\n",
      "INFO - 10:14:26: EPOCH 9 - PROGRESS: at 71.43% examples, 45431 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:26: EPOCH - 9 : training on 581252 raw words (66534 effective words) took 1.2s, 55074 effective words/s\n",
      "INFO - 10:14:27: EPOCH 10 - PROGRESS: at 42.86% examples, 29901 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:27: EPOCH - 10 : training on 581252 raw words (66531 effective words) took 1.3s, 51995 effective words/s\n",
      "INFO - 10:14:28: EPOCH 11 - PROGRESS: at 57.14% examples, 39398 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:28: EPOCH - 11 : training on 581252 raw words (66613 effective words) took 1.3s, 53150 effective words/s\n",
      "INFO - 10:14:29: EPOCH 12 - PROGRESS: at 71.43% examples, 45922 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:29: EPOCH - 12 : training on 581252 raw words (66649 effective words) took 1.2s, 55110 effective words/s\n",
      "INFO - 10:14:31: EPOCH 13 - PROGRESS: at 71.43% examples, 44255 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:31: EPOCH - 13 : training on 581252 raw words (66611 effective words) took 1.2s, 53807 effective words/s\n",
      "INFO - 10:14:32: EPOCH 14 - PROGRESS: at 71.43% examples, 44721 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:32: EPOCH - 14 : training on 581252 raw words (66662 effective words) took 1.3s, 53316 effective words/s\n",
      "INFO - 10:14:33: EPOCH 15 - PROGRESS: at 57.14% examples, 38976 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:33: EPOCH - 15 : training on 581252 raw words (66618 effective words) took 1.2s, 53327 effective words/s\n",
      "INFO - 10:14:34: EPOCH 16 - PROGRESS: at 57.14% examples, 39815 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:35: EPOCH - 16 : training on 581252 raw words (66595 effective words) took 1.2s, 53979 effective words/s\n",
      "INFO - 10:14:36: EPOCH 17 - PROGRESS: at 42.86% examples, 29004 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:36: EPOCH - 17 : training on 581252 raw words (66607 effective words) took 1.4s, 47128 effective words/s\n",
      "INFO - 10:14:37: EPOCH 18 - PROGRESS: at 42.86% examples, 26759 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:37: EPOCH - 18 : training on 581252 raw words (66568 effective words) took 1.4s, 47399 effective words/s\n",
      "INFO - 10:14:38: EPOCH 19 - PROGRESS: at 42.86% examples, 29579 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:39: EPOCH - 19 : training on 581252 raw words (66620 effective words) took 1.3s, 52224 effective words/s\n",
      "INFO - 10:14:40: EPOCH 20 - PROGRESS: at 57.14% examples, 38894 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:40: EPOCH - 20 : training on 581252 raw words (66644 effective words) took 1.2s, 53878 effective words/s\n",
      "INFO - 10:14:41: EPOCH 21 - PROGRESS: at 57.14% examples, 39744 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:41: EPOCH - 21 : training on 581252 raw words (66597 effective words) took 1.3s, 53207 effective words/s\n",
      "INFO - 10:14:42: EPOCH 22 - PROGRESS: at 57.14% examples, 39776 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:42: EPOCH - 22 : training on 581252 raw words (66566 effective words) took 1.2s, 53254 effective words/s\n",
      "INFO - 10:14:43: EPOCH 23 - PROGRESS: at 42.86% examples, 29372 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:44: EPOCH - 23 : training on 581252 raw words (66621 effective words) took 1.3s, 50940 effective words/s\n",
      "INFO - 10:14:45: EPOCH 24 - PROGRESS: at 57.14% examples, 39313 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:45: EPOCH - 24 : training on 581252 raw words (66580 effective words) took 1.3s, 52694 effective words/s\n",
      "INFO - 10:14:46: EPOCH 25 - PROGRESS: at 57.14% examples, 38827 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:46: EPOCH - 25 : training on 581252 raw words (66510 effective words) took 1.3s, 52921 effective words/s\n",
      "INFO - 10:14:47: EPOCH 26 - PROGRESS: at 57.14% examples, 38896 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:48: EPOCH - 26 : training on 581252 raw words (66571 effective words) took 1.3s, 52272 effective words/s\n",
      "INFO - 10:14:49: EPOCH 27 - PROGRESS: at 42.86% examples, 28166 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:49: EPOCH - 27 : training on 581252 raw words (66568 effective words) took 1.4s, 49155 effective words/s\n",
      "INFO - 10:14:50: EPOCH 28 - PROGRESS: at 57.14% examples, 38626 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:50: EPOCH - 28 : training on 581252 raw words (66616 effective words) took 1.3s, 52212 effective words/s\n",
      "INFO - 10:14:51: EPOCH 29 - PROGRESS: at 42.86% examples, 29782 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:51: EPOCH - 29 : training on 581252 raw words (66571 effective words) took 1.3s, 52044 effective words/s\n",
      "INFO - 10:14:52: EPOCH 30 - PROGRESS: at 57.14% examples, 39168 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:14:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:14:53: EPOCH - 30 : training on 581252 raw words (66563 effective words) took 1.3s, 52231 effective words/s\n",
      "INFO - 10:14:53: training on a 17437560 raw words (1997741 effective words) took 37.9s, 52744 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:14:53: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the vocabulary is:  6851\n",
      "size of the corpus_count: 7\n"
     ]
    }
   ],
   "source": [
    "#word2vec_book_model(Multiple_book_list, min_count = 5, window = 3)\n",
    "#print(len(Multiple_book_list))\n",
    "list_of_local_books = bow_list_maker()\n",
    "three_book_model = word2vec_book_model(list_of_local_books, min_count = 10, window = 4, size = 400, sample = 6e-5, negative = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between alcohol  and  hydroxyl  is   0.7402404\n",
      "words most similar to carbon are: \n",
      "[('attached', 0.9968094825744629), ('carbons', 0.9901885986328125), ('hydrogens', 0.9870703816413879), ('carbon_atom', 0.9869042038917542), ('oxygen', 0.9862474799156189), ('hydrogen_atoms', 0.985282838344574), ('bonded', 0.9836483001708984), ('double_bond', 0.9827227592468262), ('breaking', 0.9747698903083801), ('four', 0.9737505912780762)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7402404"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write a quick method here for simplifying the below\n",
    "\n",
    "def model_analyzer(word2vec_model, word1_compare, word2_compare, similarity_word = \"\"):\n",
    "    #print(\"similarity between alchohol and hydroxyl is: \", new_trained_model.wv.similarity(\"alcohol\", \"hydroxyl\"))\n",
    "    compare_num =  (word2vec_model.wv.similarity(word1_compare, word2_compare))\n",
    "    print(\"similarity between\", word1_compare, \" and \", word2_compare, \" is  \", word2vec_model.wv.similarity(word1_compare, word2_compare))\n",
    "\n",
    "     \n",
    "    if similarity_word != \"\":\n",
    "        print(\"words most similar to\", similarity_word, \"are: \")\n",
    "        print(word2vec_model.wv.most_similar(positive=[similarity_word], topn = 10))\n",
    "\n",
    "    return compare_num\n",
    "\n",
    "\n",
    "model_analyzer(three_book_model, \"alcohol\", \"hydroxyl\", similarity_word = \"carbon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between electrophile  and  nucleophile  is   0.8939026\n",
      "similarity between acid  and  base  is   0.93316615\n",
      "similarity between polar  and  nonpolar  is   0.94328654\n",
      "similarity between synthetic  and  natural  is   0.96645224\n",
      "similarity between positive  and  negative  is   0.99771947\n",
      "similarity between simple  and  complex  is   0.9166586\n",
      "ant avg:  0.9418641726175944\n",
      "\n",
      "similarity between carbon  and  nitrogen  is   0.9730783\n",
      "similarity between ketone  and  carbonyl  is   0.90407205\n",
      "similarity between alcohol  and  hydroxyl  is   0.7402404\n",
      "similarity between proton  and  hydrogen  is   0.8267946\n",
      "similarity between polymer  and  chain  is   0.6491602\n",
      "similarity between electron  and  negative  is   0.8734058\n",
      "syn avg:  0.8277919292449951\n"
     ]
    }
   ],
   "source": [
    "def syn_ant_tester(nn_model):\n",
    "\n",
    "    elec_nuc = model_analyzer(nn_model, \"electrophile\", \"nucleophile\")   #opposites\n",
    "    acid_base = model_analyzer(nn_model,\"acid\", \"base\")      #opposites\n",
    "    polar_nonpol = model_analyzer(nn_model,\"polar\", \"nonpolar\")   #opposites\n",
    "    synth_nat = model_analyzer(nn_model,\"synthetic\", \"natural\")   #opposites\n",
    "    pos_neg = model_analyzer(nn_model,\"positive\", \"negative\")   #opposites\n",
    "    #fs = model_analyzer(nn_model,\"fast\", \"slow\")   #opposites\n",
    "    #db = model_analyzer(nn_model,\"dark\", \"bright\")   #opposites\n",
    "    sc = model_analyzer(nn_model,\"simple\", \"complex\")   #opposites\n",
    "    #mc = model_analyzer(nn_model,\"polyamides\", \"ligand\")   #opposites\n",
    "\n",
    "    ant_avg = (elec_nuc+acid_base+polar_nonpol+synth_nat+pos_neg+sc)/6\n",
    "    print(\"ant avg: \", ant_avg)\n",
    "    print()\n",
    "    #print(type(nn_model.wv.vocab))\n",
    "    cn = model_analyzer(nn_model,\"carbon\", \"nitrogen\")  #related- same ish\n",
    "    kc = model_analyzer(nn_model,\"ketone\", \"carbonyl\") #same ish \n",
    "    ah = model_analyzer(nn_model,\"alcohol\", \"hydroxyl\")  #same\n",
    "    ph = model_analyzer(nn_model,\"proton\", \"hydrogen\")  #same  \n",
    "    pc = model_analyzer(nn_model,\"polymer\", \"chain\")  #same\n",
    "    en = model_analyzer(nn_model,\"electron\", \"negative\")  #same\n",
    "    #hw = model_analyzer(nn_model,\"water\", \"h2o\")  #same\n",
    "    \n",
    "\n",
    "    syn_avg = (cn+kc+ah+ph+pc+en)/6\n",
    "    print(\"syn avg: \", syn_avg)\n",
    "\n",
    "\n",
    "syn_ant_tester(three_book_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#word2vec_book_model(min_count = 3, window = 4, size = 300, sample = 6e-5, negative = 10) - good settings from capstone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ravve_Soder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0e10df721a31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msyn_ant_tester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRavve_Soder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(Schaller_Model.wv.vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ravve_Soder' is not defined"
     ]
    }
   ],
   "source": [
    "syn_ant_tester(Ravve_Soder)\n",
    "#print(Schaller_Model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
