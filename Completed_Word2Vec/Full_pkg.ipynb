{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The purpose of this notebook is to write a .py callable program which does five things: 1) create a word2vec neural network 2) optimize the parameters for\n",
    "NN creation 3) save the NN 4) graph the data, and 5) make the word embeddings compatible with the embeddings created by BERT. Not neccessarily in that order.\n",
    "It should take in the locationof a data corpus, the desired name of the saved NN\"\"\"\n",
    "\n",
    "#need to double check if we need these if they're already in Lousia's functions\n",
    "import re, string \n",
    "import pandas as pd \n",
    "from time import time  \n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, PreTrainedTokenizer\n",
    "import csv\n",
    "import glob \n",
    "\n",
    "#louisa's functions imported from local download as .py, added lines = true to fix value error when reading json into df\n",
    "import Louisa_w2v_functions as w2v_functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a quick function that prompts the user for a local corpus folder name then reads all the jsons in it, they then can be all cleaned w/ Louisa's clean\n",
    "#function or a one I wrote\n",
    "\n",
    "#w2v_functions.feed2vec(r\"C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json\", tokenize = True )\n",
    "\n",
    "def super_list_maker():\n",
    "    \"\"\"this function prompts the user for a local folder/corpus location, where all the json's are located. It then reads all of them into a list.\n",
    "    Currently it reads them into a list of lists, where each book is a list. Might be useful to have this distinction\"\"\"\n",
    "    initPath = input(\"Enter a file location\")\n",
    "    bookType = input(\"Enter a data type(.json please)\")\n",
    "    token_list = []\n",
    "    final_list = []\n",
    "    if bookType:\n",
    "        path = initPath + \"\\*\" + bookType\n",
    "    else:\n",
    "        path = initPath\n",
    "    raw_path = r\"{}\".format(path)\n",
    "    bookList = glob.glob(raw_path)\n",
    "    \n",
    "    yesOrNo = input(\"Is there an additional file type? (y or n) \")\n",
    "    if yesOrNo == \"y\":\n",
    "        bookType2 = input(\"Enter a second data type(.txt) \")\n",
    "        path2 = initPath + \"\\*\" + bookType2\n",
    "        raw_path2 = r\"{}\".format(path2)\n",
    "        bookList2 = glob.glob(raw_path2)\n",
    "        for bookSite in bookList2:\n",
    "            bookList.append(bookSite)\n",
    "    \n",
    "    bookCount = len(bookList)\n",
    "    print(\"bookCount is \", bookCount)\n",
    "    print(\"book list is \", bookList)\n",
    "\n",
    "    for i in range(bookCount): #(len(bookList)):\n",
    "        sep_book_list = w2v_functions.feed2vec(bookList[i], tokenize = True)\n",
    "        print(\"token list as of book \", i+1, \"is \", sep_book_list)\n",
    "        print(\"tokens in book \", i+1, \"is\", len(sep_book_list[0]))\n",
    "        print()\n",
    "        for word in sep_book_list:\n",
    "            token_list.append(word)  #use true here\n",
    "        print(\"data type of token_list[\", i, \"]\", type(token_list[i]))\n",
    "        if type(token_list[i]) == list:\n",
    "            for subtoken in token_list[i]:\n",
    "                final_list.append(subtoken)\n",
    "\n",
    "    print()\n",
    "    print(\"number of books \", len(token_list) + 1)\n",
    "    print(\"final list length/token count \", len(final_list))\n",
    "    print (\"all tokens \", final_list)\n",
    "    return final_list\n",
    "    print()\n",
    "\n",
    "    \n",
    "#local book path = C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files   this format is what works, then use .json as type  \n",
    "#super_list_maker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a file location C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\n",
      "Enter a data type(.json please) .json\n",
      "Is there an additional file type? (y or n)  y\n",
      "Enter a second data type(.txt)  .txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookCount is  7\n",
      "book list is  ['C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Polymer_Chemistry_by_Koltzsenburg_Maskos_and_Nuyken.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Polymer_Synthesis_Theory_and_Practice_by_Braun_Cherdron_Rehahn_Ritter_and_Voit.json', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Basic Principles of Organic Chemistry (Roberts and Caserio).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Logic of Organic Synthesis (Rao).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Book Organic Chemistry - A Carbonyl Early Approach (McMichael).txt', 'C:\\\\Users\\\\bowri\\\\square1\\\\ChemLP\\\\Bowman\\\\textbook_files\\\\Soderberg_bio_o_chem.txt']\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Brewing_Science_A_Multidisciplinary_Approach_by_Mosher_and_Trantham.json\n",
      "                                                   0\n",
      "0  michael mosher · kenneth trantham  brewing  sc...\n",
      "1  all rights are reserved by the publisher, whet...\n",
      "2  the use of general descriptive names, register...\n",
      "3  the publisher, the authors and the editors are...\n",
      "4  neither the publisher nor the authors or the e...\n",
      "5                     trademarks, service marks, etc\n",
      "6   printed on acid-free paper  this springer imp...\n",
      "7  thus began the discussion for the beginnings o...\n",
      "8  “wouldn’t it be awesome,” we thought, “if we c...\n",
      "9              the result is what you will find here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  1 is  [['0', 'michael', 'moshe', '##r', '·', 'kenneth', 'tran', '##tham', 'brewing', 'sci', '##e', '.', '.', '.', '1', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '2', 'use', 'general', 'descriptive', 'names', 'registered', 'names', '.', '.', '.', '3', 'publisher', 'authors', 'editors', 'safe', 'assume', 'advice', 'i', '.', '.', '.', '4', 'neither', 'publisher', 'authors', 'editors', 'give', 'warrant', '.', '.', '.', '.', '.', '.', '131', '##7', '##6', '131', '##7', '##7', 'k', 'g', 'k', 'j', 'k', 'p', 'r', 'n', 'e', 'g', 'k', 'j', 'k', 'p', 'l', 'h', 'n', 'e', 'g', 'k', 'j', 'k', 'g', '.', '.', '.', '131', '##7', '##8', 'b', 'e', 'l', 'b', 'appendix', 'b', 'ref', '##ri', '##ger', '##ant', 'data', 'table', 'su', '##pe', '.', '.', '.', '131', '##7', '##9', 'moshe', '##r', 'k', '131', '##80', 'tran', '##tham', 'brewing', 'science', 'multi', '##dis', '##ci', '##plin', '##ary', 'app', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '81', '##7', '##9', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  1 is 146\n",
      "\n",
      "data type of token_list[ 0 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Polymer_Chemistry_by_Koltzsenburg_Maskos_and_Nuyken.json\n",
      "                                                   0\n",
      "0  sebastian koltzenburg michael maskos oskar nuy...\n",
      "1  all rights are reserved by the publisher, whet...\n",
      "2  the  use  of  general  descriptive  names,  re...\n",
      "3   in  this  publication does not imply, even in...\n",
      "4  the publisher, the authors and the editors are...\n",
      "5   neither  the  publisher  nor  the  authors or...\n",
      "6   cover illustration: with kind permission by g...\n",
      "7   all computer chips used in our desktops, lapt...\n",
      "8   cutting-edge  biomedical  applications  requi...\n",
      "9  the interior of every automobile is almost ent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  2 is  [['0', 'sebastian', 'ko', '##lt', '##zen', '##burg', 'michael', 'mask', '##os', 'oskar', 'nu', '##y', '.', '.', '.', '1', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '2', 'use', 'general', 'descriptive', 'names', 'registered', 'names', '.', '.', '.', '3', 'publication', 'imply', 'even', 'absence', 'specific', 'state', '##m', '.', '.', '.', '4', 'publisher', 'authors', 'editors', 'safe', 'assume', 'advice', 'i', '.', '.', '.', '.', '.', '.', '950', '##4', 'see', 'blow', 'mold', '##ing', 'f', 'fenton', '’', 's', 're', '##age', '##nt', 'fiber', '##re', '##in', '##f', '.', '.', '.', '950', '##5', 'gut', '##ta', 'perch', '##a', 'h', 'ha', '##f', '##nium', 'half', '##san', '##d', '##wich', 'compound', 'h', '.', '.', '.', '950', '##6', 'see', 'poly', '##eth', '##er', 'ke', '##tone', 'pe', '##k', 'pe', '##llet', '##izing', 'cold', 'pe', '##ll', '.', '.', '.', '950', '##7', 'see', 'forming', 'processes', 'resin', 'transfer', 'mold', '##ing', 'r', '.', '.', '.', '950', '##8', 'sc', '##hul', '##z', '##fl', '##ory', 'distribution', 'second', '##ord', '##er', 'transit', '##io', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '86', '##8', '##2', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  2 is 162\n",
      "\n",
      "data type of token_list[ 1 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Polymer_Synthesis_Theory_and_Practice_by_Braun_Cherdron_Rehahn_Ritter_and_Voit.json\n",
      "                                                   0\n",
      "0          polymer synthesis: theory and practice   \n",
      "1    dietrich braun (29) harald cherdron matthias...\n",
      "2  dresden germany  isbn 978-3-642-28979-8 doi 10...\n",
      "3  all rights are reserved by the publisher, whet...\n",
      "4  exempted from this legal reservation are brief...\n",
      "5  duplication of this publication or parts there...\n",
      "6  permissions for use may be obtained through ri...\n",
      "7  violations are liable to prosecution under the...\n",
      "8  the use of general descriptive names, register...\n",
      "9  in this publication does not imply, even in th...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  3 is  [['0', 'polymer', 'synthesis', 'theory', 'practice', '1', 'dietrich', 'braun', 'harald', 'cher', '##dron', 'matthias', 're', '##ha', '##hn', '.', '.', '.', '2', 'dresden', 'germany', 'isbn', 'doi', 'springer', 'heidelberg', 'n', '.', '.', '.', '3', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '4', 'exempt', '##ed', 'legal', 'reservation', 'brief', 'excerpts', 'con', '##n', '.', '.', '.', '.', '.', '.', '122', '##60', 'braun', 'et', 'al', 'polymer', 'synthesis', 'theory', 'practice', '.', '.', '.', '122', '##6', '##1', 'see', 'organic', 'field', '##ef', '##fect', 'trans', '##isto', '##r', 'of', '##et', 'ole', '##d', '122', '##6', '##2', 'see', 'organic', 'light', 'emi', '##tting', 'di', '##ode', 'ole', '##d', 'ol', '##igo', '##mer', '.', '.', '.', '122', '##6', '##3', 'see', 'organic', 'photo', 'voltage', 'op', '##v', 'organic', 'field', '##ef', '##f', '.', '.', '.', '122', '##64', 'see', 'polymer', 'based', 'organic', 'light', 'emi', '##tting', 'di', '##ode', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '70', '##57', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  3 is 143\n",
      "\n",
      "data type of token_list[ 2 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Basic Principles of Organic Chemistry (Roberts and Caserio).txt\n",
      "                                                   0\n",
      "0  1: Introduction to Organic Chemistry: You now ...\n",
      "1  2: Structural Organic Chemistry: This chapter ...\n",
      "2  3: Organic Nomenclature: A chemical nomenclatu...\n",
      "3  4: Alkanes: Alkanes are the simplest organic m...\n",
      "4  5: Stereoisomerism of Organic Molecules: Posit...\n",
      "5  6: Bonding in Organic Molecules: Remembering t...\n",
      "6  7: Other Compounds than Hydrocarbons: We begin...\n",
      "7  8: Nucleophilic Substitution and Elimination R...\n",
      "8  9: Separation, Purification, & Identification ...\n",
      "9  10: Alkenes and Alkynes I - Ionic and Radical ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  4 is  [['0', 'introduction', 'organic', 'chemistry', 'starting', 'study', '.', '.', '.', '1', 'structural', 'organic', 'chemistry', 'chapter', 'briefly', 'r', '.', '.', '.', '2', 'organic', 'nomenclature', 'chemical', 'nomenclature', 'set', '.', '.', '.', '3', 'al', '##kan', '##es', 'al', '##kan', '##es', 'simplest', 'organic', 'molecules', 'con', '.', '.', '.', '4', 'stereo', '##iso', '##mer', '##ism', 'organic', 'molecules', 'position', 'iso', '.', '.', '.', '.', '.', '.', '71', '##50', 'show', 'mechanisms', 'combination', 'others', 'described', 'c', '.', '.', '.', '71', '##51', 'ch', 'ch', 'pd', '##cl', 'h', 'ch', '71', '##52', 'reaction', 'used', 'large', '##sca', '##le', 'production', 'ox', '##idi', '##zing', '.', '.', '.', '71', '##53', 'b', 'balance', 'competitive', 'nu', '##cle', '##op', '##hil', '##ic', 'reactions', 'd', '.', '.', '.', '71', '##54', 'write', 'me', '##chan', '##istic', 'steps', 'account', 'difference', 'ste', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '67', '##42', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  4 is 131\n",
      "\n",
      "data type of token_list[ 3 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Logic of Organic Synthesis (Rao).txt\n",
      "                                                   0\n",
      "0                  1: Synthesis of Organic Molecules\n",
      "1  2: Rules and Guidelines Governing Organic Synt...\n",
      "2          Baldwin’s Rule for Ring Closure Reactions\n",
      "3                                       Bredt's Rule\n",
      "4                      Cram's Rule and Prelog's Rule\n",
      "5                  Hofmann’s Rule and Zaitsev’s Rule\n",
      "6                                   Markovnikov Rule\n",
      "7   3: Criteria for Selection of the Synthetic Route\n",
      "8                          4: The Logic of Synthesis\n",
      "9              5: Strategies in Disparlure Synthesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  5 is  [['0', 'synthesis', 'organic', 'molecules', '1', 'rules', 'guidelines', 'governing', 'organic', 'synthesis', '2', 'baldwin', '’', 's', 'rule', 'ring', 'closure', 'reactions', '3', 'bred', '##ts', 'rule', '4', 'cr', '##ams', 'rule', 'pre', '##log', '##s', 'rule', '.', '.', '.', '580', 'fig', '58', '##1', 'use', 'transition', 'metal', 're', '##age', '##nts', 'could', 'aid', 'con', '##st', '##r', '.', '.', '.', '58', '##2', 'fig', '58', '##3', 'rare', 'molecular', 'engineering', 'marvel', '##s', 'like', 'rb', 'woo', '.', '.', '.', '58', '##4', 'doubt', 'feasibility', 'protection', 'free', 'synthesis', 'co', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '49', '##9', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  5 is 91\n",
      "\n",
      "data type of token_list[ 4 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Book Organic Chemistry - A Carbonyl Early Approach (McMichael).txt\n",
      "                                                   0\n",
      "0    1: Carbonyl Group: Notation, Structure, Bonding\n",
      "1        2: Functional Groups, Hybridization, Naming\n",
      "2       3: Additions: Electrophilic and Nucleophilic\n",
      "3          4: Acetal Formation, Mechanism, Resonance\n",
      "4         5: Nitrogen Nucleophiles - Imine Formation\n",
      "5          6: Addition of Organometallics - Grignard\n",
      "6        7: Oxidation & Reduction, alpha-C-H acidity\n",
      "7         8: Enolates, Aldol Condensation, Synthesis\n",
      "8    9: Carboxylic Acid Derivatives: Interconversion\n",
      "9  10: Carboxylic Acid Derivatives - Alpha Carbon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  6 is  [['0', 'carbon', '##yl', 'group', 'notation', 'structure', 'bonding', '1', 'functional', 'groups', 'hybrid', '##ization', 'naming', '2', 'additions', 'electro', '##phi', '##lic', 'nu', '##cle', '##op', '##hil', '##ic', '3', 'ace', '##tal', 'formation', 'mechanism', 'resonance', '4', 'nitrogen', 'nu', '##cle', '##op', '##hil', '##es', 'im', '##ine', 'formation', '.', '.', '.', '101', '##8', 'finally', 'lets', 'return', 'another', 'application', 'free', 'r', '.', '.', '.', '102', '##0', 'new', 'molecule', 'would', 'also', 'free', 'radical', 'could', 'add', '.', '.', '.', '102', '##1', 'polymer', '##ization', 'reactions', 'also', 'important', 'table', '.', '.', '.', '102', '##3', 'since', 'repeating', 'unit', 'formed', 'adding', 'end', 'double', '.', '.', '.', '102', '##4', 'kirk', 'mc', '##mic', '##hae', '##l', 'washington', 'state', 'university', 'name', ':', 'text', ',', 'length', ':', '84', '##8', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  6 is 113\n",
      "\n",
      "data type of token_list[ 5 ] <class 'list'>\n",
      "filepath is  C:\\Users\\bowri\\square1\\ChemLP\\Bowman\\textbook_files\\Soderberg_bio_o_chem.txt\n",
      "                                                   0\n",
      "0  1: Introduction to Organic Structure and Bondi...\n",
      "1  2: Introduction to Organic Structure and Bondi...\n",
      "2               3: Conformations and Stereochemistry\n",
      "3  4: Structure Determination I- UV-Vis and Infra...\n",
      "4  5: Structure Determination Part II - Nuclear M...\n",
      "5                  6: Overview of Organic Reactivity\n",
      "6                             7: Acid-base Reactions\n",
      "7             8: Nucleophilic Substitution Reactions\n",
      "8  9: Phosphate Transfer Reactions: This chapter ...\n",
      "9       10: Nucleophilic Carbonyl Addition Reactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token list as of book  7 is  [['0', 'introduction', 'organic', 'structure', 'bonding', 'chapter', '.', '.', '.', '1', 'introduction', 'organic', 'structure', 'bonding', 'ii', '2', 'conform', '##ations', 'stereo', '##chemist', '##ry', '3', 'structure', 'determination', 'uv', '##vis', 'infrared', 'spec', '##tro', '.', '.', '.', '4', 'structure', 'determination', 'part', 'ii', 'nuclear', 'magnet', '.', '.', '.', '.', '.', '.', '425', '##6', 'phase', '425', '##7', 'phase', '425', '##8', 'organic', 'chemistry', 'biological', 'emphasis', 'tim', 'so', '##de', '.', '.', '.', '425', '##9', 'completing', 'chapter', 'able', '42', '##60', 'organic', 'chemistry', 'biological', 'emphasis', 'tim', 'so', '##de', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '40', '##8', '##1', ',', 'dt', '##ype', ':', 'object']]\n",
      "tokens in book  7 is 94\n",
      "\n",
      "data type of token_list[ 6 ] <class 'list'>\n",
      "\n",
      "number of books  8\n",
      "final list length/token count  880\n",
      "all tokens  ['0', 'michael', 'moshe', '##r', '·', 'kenneth', 'tran', '##tham', 'brewing', 'sci', '##e', '.', '.', '.', '1', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '2', 'use', 'general', 'descriptive', 'names', 'registered', 'names', '.', '.', '.', '3', 'publisher', 'authors', 'editors', 'safe', 'assume', 'advice', 'i', '.', '.', '.', '4', 'neither', 'publisher', 'authors', 'editors', 'give', 'warrant', '.', '.', '.', '.', '.', '.', '131', '##7', '##6', '131', '##7', '##7', 'k', 'g', 'k', 'j', 'k', 'p', 'r', 'n', 'e', 'g', 'k', 'j', 'k', 'p', 'l', 'h', 'n', 'e', 'g', 'k', 'j', 'k', 'g', '.', '.', '.', '131', '##7', '##8', 'b', 'e', 'l', 'b', 'appendix', 'b', 'ref', '##ri', '##ger', '##ant', 'data', 'table', 'su', '##pe', '.', '.', '.', '131', '##7', '##9', 'moshe', '##r', 'k', '131', '##80', 'tran', '##tham', 'brewing', 'science', 'multi', '##dis', '##ci', '##plin', '##ary', 'app', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '81', '##7', '##9', ',', 'dt', '##ype', ':', 'object', '0', 'sebastian', 'ko', '##lt', '##zen', '##burg', 'michael', 'mask', '##os', 'oskar', 'nu', '##y', '.', '.', '.', '1', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '2', 'use', 'general', 'descriptive', 'names', 'registered', 'names', '.', '.', '.', '3', 'publication', 'imply', 'even', 'absence', 'specific', 'state', '##m', '.', '.', '.', '4', 'publisher', 'authors', 'editors', 'safe', 'assume', 'advice', 'i', '.', '.', '.', '.', '.', '.', '950', '##4', 'see', 'blow', 'mold', '##ing', 'f', 'fenton', '’', 's', 're', '##age', '##nt', 'fiber', '##re', '##in', '##f', '.', '.', '.', '950', '##5', 'gut', '##ta', 'perch', '##a', 'h', 'ha', '##f', '##nium', 'half', '##san', '##d', '##wich', 'compound', 'h', '.', '.', '.', '950', '##6', 'see', 'poly', '##eth', '##er', 'ke', '##tone', 'pe', '##k', 'pe', '##llet', '##izing', 'cold', 'pe', '##ll', '.', '.', '.', '950', '##7', 'see', 'forming', 'processes', 'resin', 'transfer', 'mold', '##ing', 'r', '.', '.', '.', '950', '##8', 'sc', '##hul', '##z', '##fl', '##ory', 'distribution', 'second', '##ord', '##er', 'transit', '##io', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '86', '##8', '##2', ',', 'dt', '##ype', ':', 'object', '0', 'polymer', 'synthesis', 'theory', 'practice', '1', 'dietrich', 'braun', 'harald', 'cher', '##dron', 'matthias', 're', '##ha', '##hn', '.', '.', '.', '2', 'dresden', 'germany', 'isbn', 'doi', 'springer', 'heidelberg', 'n', '.', '.', '.', '3', 'rights', 'reserved', 'publisher', 'whether', 'whole', 'part', 'm', '.', '.', '.', '4', 'exempt', '##ed', 'legal', 'reservation', 'brief', 'excerpts', 'con', '##n', '.', '.', '.', '.', '.', '.', '122', '##60', 'braun', 'et', 'al', 'polymer', 'synthesis', 'theory', 'practice', '.', '.', '.', '122', '##6', '##1', 'see', 'organic', 'field', '##ef', '##fect', 'trans', '##isto', '##r', 'of', '##et', 'ole', '##d', '122', '##6', '##2', 'see', 'organic', 'light', 'emi', '##tting', 'di', '##ode', 'ole', '##d', 'ol', '##igo', '##mer', '.', '.', '.', '122', '##6', '##3', 'see', 'organic', 'photo', 'voltage', 'op', '##v', 'organic', 'field', '##ef', '##f', '.', '.', '.', '122', '##64', 'see', 'polymer', 'based', 'organic', 'light', 'emi', '##tting', 'di', '##ode', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '70', '##57', ',', 'dt', '##ype', ':', 'object', '0', 'introduction', 'organic', 'chemistry', 'starting', 'study', '.', '.', '.', '1', 'structural', 'organic', 'chemistry', 'chapter', 'briefly', 'r', '.', '.', '.', '2', 'organic', 'nomenclature', 'chemical', 'nomenclature', 'set', '.', '.', '.', '3', 'al', '##kan', '##es', 'al', '##kan', '##es', 'simplest', 'organic', 'molecules', 'con', '.', '.', '.', '4', 'stereo', '##iso', '##mer', '##ism', 'organic', 'molecules', 'position', 'iso', '.', '.', '.', '.', '.', '.', '71', '##50', 'show', 'mechanisms', 'combination', 'others', 'described', 'c', '.', '.', '.', '71', '##51', 'ch', 'ch', 'pd', '##cl', 'h', 'ch', '71', '##52', 'reaction', 'used', 'large', '##sca', '##le', 'production', 'ox', '##idi', '##zing', '.', '.', '.', '71', '##53', 'b', 'balance', 'competitive', 'nu', '##cle', '##op', '##hil', '##ic', 'reactions', 'd', '.', '.', '.', '71', '##54', 'write', 'me', '##chan', '##istic', 'steps', 'account', 'difference', 'ste', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '67', '##42', ',', 'dt', '##ype', ':', 'object', '0', 'synthesis', 'organic', 'molecules', '1', 'rules', 'guidelines', 'governing', 'organic', 'synthesis', '2', 'baldwin', '’', 's', 'rule', 'ring', 'closure', 'reactions', '3', 'bred', '##ts', 'rule', '4', 'cr', '##ams', 'rule', 'pre', '##log', '##s', 'rule', '.', '.', '.', '580', 'fig', '58', '##1', 'use', 'transition', 'metal', 're', '##age', '##nts', 'could', 'aid', 'con', '##st', '##r', '.', '.', '.', '58', '##2', 'fig', '58', '##3', 'rare', 'molecular', 'engineering', 'marvel', '##s', 'like', 'rb', 'woo', '.', '.', '.', '58', '##4', 'doubt', 'feasibility', 'protection', 'free', 'synthesis', 'co', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '49', '##9', ',', 'dt', '##ype', ':', 'object', '0', 'carbon', '##yl', 'group', 'notation', 'structure', 'bonding', '1', 'functional', 'groups', 'hybrid', '##ization', 'naming', '2', 'additions', 'electro', '##phi', '##lic', 'nu', '##cle', '##op', '##hil', '##ic', '3', 'ace', '##tal', 'formation', 'mechanism', 'resonance', '4', 'nitrogen', 'nu', '##cle', '##op', '##hil', '##es', 'im', '##ine', 'formation', '.', '.', '.', '101', '##8', 'finally', 'lets', 'return', 'another', 'application', 'free', 'r', '.', '.', '.', '102', '##0', 'new', 'molecule', 'would', 'also', 'free', 'radical', 'could', 'add', '.', '.', '.', '102', '##1', 'polymer', '##ization', 'reactions', 'also', 'important', 'table', '.', '.', '.', '102', '##3', 'since', 'repeating', 'unit', 'formed', 'adding', 'end', 'double', '.', '.', '.', '102', '##4', 'kirk', 'mc', '##mic', '##hae', '##l', 'washington', 'state', 'university', 'name', ':', 'text', ',', 'length', ':', '84', '##8', ',', 'dt', '##ype', ':', 'object', '0', 'introduction', 'organic', 'structure', 'bonding', 'chapter', '.', '.', '.', '1', 'introduction', 'organic', 'structure', 'bonding', 'ii', '2', 'conform', '##ations', 'stereo', '##chemist', '##ry', '3', 'structure', 'determination', 'uv', '##vis', 'infrared', 'spec', '##tro', '.', '.', '.', '4', 'structure', 'determination', 'part', 'ii', 'nuclear', 'magnet', '.', '.', '.', '.', '.', '.', '425', '##6', 'phase', '425', '##7', 'phase', '425', '##8', 'organic', 'chemistry', 'biological', 'emphasis', 'tim', 'so', '##de', '.', '.', '.', '425', '##9', 'completing', 'chapter', 'able', '42', '##60', 'organic', 'chemistry', 'biological', 'emphasis', 'tim', 'so', '##de', '.', '.', '.', 'name', ':', 'text', ',', 'length', ':', '40', '##8', '##1', ',', 'dt', '##ype', ':', 'object']\n",
      "made it here!\n",
      "Time to train the model: 0.0 mins"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function needs to take in a list of tokens, set them as the global tokens value for Louisa's functions then train the model with them and return\n",
    "the word embeddings\n",
    "\"\"\"\n",
    "\n",
    "#take in a vocab list\n",
    "\n",
    "list_of_tokens = super_list_maker()\n",
    "#saveName = input(\"Enter a name for the model saved: \")\n",
    "w2v_functions.tokens = list_of_tokens\n",
    "w2v_functions.w2v_train(\"fourBook\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function/part can handle the TSNE graphing, display to user and such\"\"\"\n",
    "\n",
    "#def grapher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main part of the program here. Call all the functions? Save the model/embeddings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
