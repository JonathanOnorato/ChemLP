{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Scraper for Books from Chem.Libretexts\n",
    "\n",
    "## Overview\n",
    "\n",
    "The following text scraper <code> chemlibertexts_book_parser (ul) <code> extracts texts from books in the <a href ='https://chem.libretexts.org/Bookshelves' target = \"_black\"> Chem.Libretexts</a> website and store them as a JSON file with under the name of the book that one want to scrape.\n",
    "    \n",
    "The function one variable <code> url <code> which can be any book webpage from Chemlibertexts. Although most books have the same html structure, there are couple exceptions. Therefore depending on the type of the book different webelements are used to extract hyperlinks.\n",
    "\n",
    "Also, note that for webdriver, we used chrome. Please adjust it according to the type of webdriver you prefer using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import all the neccesery libararies and modules\n",
    "\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import random\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "from selenium.common.exceptions import StaleElementReferenceException \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "def chemlibertexts_book_parser(url):\n",
    "    \"\"\"\"This function takes one variable 'url' (a book chapter url from Chem.Libretexts)\"\"\" \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(random.randint(1,30)) \n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(random.randint(1,100))\n",
    "    \n",
    "    # first the driver finds the title of the book and stores under variable 'book_title' which we use later as a filename to store the parsed data\n",
    "    book_title = driver.find_element(By.XPATH, '//*[@id=\"title\"]').text.strip()\n",
    "    \n",
    "    # Next let's collect the hyperlinks of book chapters. \n",
    "    # Depending on the style of books in the chemlibertexts website we need to use different webelements as seen blow;\n",
    "    # In order to avoid the 'NoSuchElementException' error 'try and except'conditions are used. \n",
    "    # the first \"try and except\" is for books that we need to click to the table of contens page, requires two clicks and all chapters are listed under table of contens \n",
    "    # the second \"try and except\" is for books (which is more common in the website) that have main-chapter-hyperlinks on the book homepage\n",
    "    # then we need to click mainchapter to get subchapterhyperlikns \n",
    "    \n",
    "    chapter_titles = []\n",
    "    chapter_links = [] \n",
    "    chapter_summary = []\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, 'mt-icon-next-article').click()\n",
    "        driver.page_source\n",
    "        driver.find_element(By.XPATH, '//*[@title=\"Table of Contents\"]').click()\n",
    "        chapter_content_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "        chapter_link_container = chapter_content_container.find_elements(By.TAG_NAME,'a')\n",
    "        chapter_links = [link.get_attribute('href') for link in chapter_link_container]\n",
    "        chapter_titles = [link.text.strip() for link in chapter_link_container]\n",
    "        chapter_summary_container = chapter_container.find_elements(By.CLASS_NAME, 'summary')\n",
    "        chapter_summary = [summary.text.strip() for summary in chapter_summary_container]\n",
    "    except:\n",
    "        NoSuchElementException\n",
    "    \n",
    "    try:\n",
    "        chapter_container = driver.find_element(By.CLASS_NAME, 'mt-sortable-listings-container')\n",
    "        chapter_link_container = chapter_container.find_elements(By.TAG_NAME,'a')\n",
    "        for chapter_link in chapter_link_container:\n",
    "            if 'Front Matter' in chapter_link.get_attribute('title'):\n",
    "                pass\n",
    "            elif 'Back Matter' in chapter_link.get_attribute('title'):\n",
    "                pass\n",
    "    \n",
    "            else:\n",
    "                chapter_links.append(chapter_link.get_attribute('href'))\n",
    "                chapter_titles.append(chapter_link.get_attribute('title'))\n",
    "    except:\n",
    "        NoSuchElementException \n",
    "            \n",
    "    print('Name of book', book_title, '\\n', 'Number of chapters is', len(chapter_titles))\n",
    "    \n",
    "     # Following for loop go through the chapter_links collected above and looks for subchapter hyperlinks\n",
    "    # And also looks for overviews. Aagain, to avoid the 'NoSuchElementException' following 'try and except'condition is used\n",
    "    \n",
    "    subchapter_links = []\n",
    "    subchapter_titles = []\n",
    "    subchapter_link_container = []\n",
    "    \n",
    "    for chapter in list(dict.fromkeys(chapter_links)):\n",
    "        driver.get(chapter)\n",
    "        driver.page_source  \n",
    "        try:\n",
    "            subchapter_container = driver.find_element(By.CLASS_NAME, 'noindex')\n",
    "            subchapter_link_container = subchapter_container.find_elements(By.TAG_NAME,'a')\n",
    "            for link in subchapter_link_container:\n",
    "                subchapter_links.append(link.get_attribute('href'))\n",
    "                subchapter_titles.append(link.get_attribute('title'))\n",
    "        except:\n",
    "            NoSuchElementException\n",
    "            \n",
    "     # After collectong all chapter and subchapter links, let's combine all hyperlinks\n",
    "    # Before looping through the links let's remove duplicates;\n",
    "    # because for some books, all chapter hyperlinks including subchapters are given in one page;\n",
    "    # so that when we collect subchapters, we endup having the same list for two times!\n",
    "    \n",
    "    total_chapter_titles = list(dict.fromkeys(chapter_titles + subchapter_titles))\n",
    "    total_chapter_links = list(dict.fromkeys(chapter_links + subchapter_links))\n",
    "    \n",
    "        \n",
    "    chapter_contents = [] \n",
    "    \n",
    "    # in order to avoid duplicated looping over chapterlinks for the first types of book the following if conditions are applied\n",
    "    \n",
    "    if len(chapter_links) > len(subchapter_links):\n",
    "        for link in list(dict.fromkeys(chapter_links)):\n",
    "            driver.get(link)\n",
    "            driver.page_source\n",
    "            chapter_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "            subchapter_text_container = chapter_container.find_elements(By.XPATH,'//*[@id=\"elm-main-content\"]/section/p') \n",
    "            for subchap in subchapter_text_container:\n",
    "                chapter_contents.append(subchap.text.strip())\n",
    "    else:\n",
    "        for link in total_chapter_links:\n",
    "            driver.get(link)\n",
    "            driver.page_source\n",
    "            chapter_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "            subchapter_text_container = chapter_container.find_elements(By.XPATH,'//*[@id=\"elm-main-content\"]/section/p') \n",
    "            for subchap in subchapter_text_container:\n",
    "                chapter_contents.append(subchap.text.strip())\n",
    "    \n",
    "    # again since we have slightly different data for the two differnt types of books, used following if condition to diffirentiate.\n",
    "    \n",
    "    if len((chapter_links)) > len(subchapter_links):       \n",
    "        data = {'chap-title':chapter_titles,'chap-summary': chapter_summary,'chap-content':chapter_contents}\n",
    "    else:\n",
    "        data = {'chap-title': total_chapter_titles,'chap-content':chapter_contents}\n",
    "    \n",
    "    filename = book_title\n",
    "    with open(filename, \"w\") as outfile:\n",
    "            json.dump(data, outfile)\n",
    "    print('Number of subchapters is', len(subchapter_links))\n",
    "    print('Number of total chapters is', len(total_chapter_links))\n",
    "    return chapter_links, chapter_titles, total_chapter_titles, driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
