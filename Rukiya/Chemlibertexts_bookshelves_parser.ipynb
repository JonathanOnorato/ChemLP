{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Scraper for Bookshelves from Chem.Libretexts\n",
    "\n",
    "## Overview\n",
    "\n",
    "The following text scraper <code> chemlibertexts_bookshelves_parser (ul) </code> extracts texts of all the books from your choice of the bookshelves in the <a href ='https://chem.libretexts.org/Bookshelves' target = \"_black\"> Chem.Libretexts</a> website and store them as a JSON file with under the name of the bookshelves that one wants to scrape.\n",
    "    \n",
    "The function has one variable <code> url </code> which can be any bookshelves page from Chemlibertexts. Although most books have the same html structure, there are couple exceptions. Therefore depending on the type of the book different webelements are used to extract hyperlinks. The function used breadth-first strategy: first it collects all the book hyperlinks. Then using these book hyperlinks to collect all chapters then subchapters. Finally, texts were scraped using a for loop through chapter and subchapter hyperlinks.\n",
    "\n",
    "I tested it for two bookshelves (Environmental Chemistry and Biochem) and worked fine.\n",
    "\n",
    "Also, note that for webdriver, we used chrome. Please adjust it according to the type of webdriver you prefer using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import all the neccesery libararies and modules\n",
    "\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import random\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "from selenium.common.exceptions import StaleElementReferenceException \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "def chemlibertexts_bookschelves_parser(url):\n",
    "    \"\"\"\"This function takes one variable 'url' a Bookshelves url from Chem.Libretexts)\"\"\" \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(random.randint(1,30)) \n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(random.randint(1,100))\n",
    "    \n",
    "    # driver collects hyperlinks of books in the bookshelves.\n",
    "    # in the bookshelves, books are distinguished by putting \"Book: xxxx\" on their title from other\n",
    "    # types of materials, such as maps, excercise, etc.\n",
    "    # we also collect the name of the bookshelves so that we can use it as file name to store the data\n",
    "    \n",
    "    book_links = []\n",
    "    book_titles_shortoverviews = []\n",
    "    bookshelves_name = driver.find_element(By.XPATH, '//*[@id=\"title\"]').text.strip()\n",
    "    main_content_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "    book_link_container = main_content_container.find_elements(By.TAG_NAME, 'a')\n",
    "    for link in book_link_container:\n",
    "        if 'Book:' in link.get_attribute('title'):\n",
    "            book_titles_shortoverviews.append(link.get_attribute('title').strip()) \n",
    "            book_links.append(link.get_attribute('href')) \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Next let's collect the hyperlinks of book chapters. \n",
    "    # Depending on the style of books in the chemlibertexts website we need to use different webelements as seen blow;\n",
    "    # In order to avoid the 'NoSuchElementException' error 'try and except'conditions are used. \n",
    "    # the first \"try and except\" is for books that we need to click to the table of contens page, requires two clicks and all chapters are listed under table of contens \n",
    "    # the second \"try and except\" is for books (which is more common in the website) that have main-chapter-hyperlinks on the book homepage\n",
    "    # then we need to click mainchapter to get subchapterhyperlikns \n",
    "    \n",
    "    book_titles = []\n",
    "    chapter_links = []\n",
    "    chapter_titles = []\n",
    "   \n",
    "    # first the driver finds the title of the book and stores under variable 'book_titles' \n",
    "    #for i in range(len(book_titles)):\n",
    "   \n",
    "    for link in book_links:\n",
    "        driver.get(link)\n",
    "        driver.page_source\n",
    "        book_titles. append(driver.find_element(By.XPATH, '//*[@id=\"title\"]').text.strip())\n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME, 'mt-icon-next-article').click()\n",
    "            driver.page_source\n",
    "            driver.find_element(By.XPATH, '//*[@title=\"Table of Contents\"]').click()\n",
    "            chapter_content_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "            chapter_link_container = chapter_content_container.find_elements(By.TAG_NAME,'a')\n",
    "            chapter_links = (link.get_attribute('href') for link in chapter_link_container)\n",
    "            chapter_titles = (link.text.strip() for link in chapter_link_container)\n",
    "        except:\n",
    "            NoSuchElementException\n",
    "            \n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//*[@id=title=\"Front Matter\"]').click()\n",
    "            driver.page_source\n",
    "            driver.find_element(By.XPATH, '//*[@title=\"Table of Contents\"]').click()\n",
    "            chapter_content_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "            chapter_link_container = chapter_content_container.find_elements(By.TAG_NAME,'a')\n",
    "            for link in chapter_link_container:\n",
    "                if \"Back Matter\" in link.text.strip():\n",
    "                    pass\n",
    "                elif \"Index\" in link.text.strip():\n",
    "                    pass\n",
    "                else:\n",
    "                    chapter_links.append(link.get_attribute('href'))\n",
    "                    chapter_titles.append(link.text.strip())       \n",
    "        except:\n",
    "            NoSuchElementException\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            chapter_container = driver.find_element(By.CLASS_NAME, 'mt-sortable-listings-container')\n",
    "            chapter_link_container = chapter_container.find_elements(By.TAG_NAME,'a')\n",
    "            for chapter_link in chapter_link_container:\n",
    "                chapter_links.append(chapter_link.get_attribute('href'))\n",
    "                chapter_titles.append(chapter_link.get_attribute('title'))\n",
    "        except:\n",
    "            NoSuchElementException\n",
    "        \n",
    "   # using the chapter hyperlinks collected let's collect subchapter lists\n",
    "    subchapter_links = []\n",
    "    subchapter_titles = []                          \n",
    "    for link in chapter_links:\n",
    "        driver.get(link)\n",
    "        driver.page_source\n",
    "        try:\n",
    "            subchapter_container = driver.find_element(By.CLASS_NAME, 'noindex')\n",
    "            subchapter_link_container = subchapter_container.find_elements(By.TAG_NAME,'a')\n",
    "            for link in subchapter_link_container:\n",
    "                subchapter_links.append(link.get_attribute('href'))\n",
    "                subchapter_titles.append(link.get_attribute('title'))\n",
    "        except:\n",
    "            NoSuchElementException\n",
    "    \n",
    "    #finally we add chapter links and subchapter links and also remove any duplicates.\n",
    "    # and loop through the total hyperlinks to parse their text content.\n",
    "    \n",
    "    total_chapter_titles = list(dict.fromkeys(chapter_titles + subchapter_titles))\n",
    "    total_chapter_links = list(dict.fromkeys(chapter_links + subchapter_links))                                                     \n",
    "                                \n",
    "    chapter_contents = total_chapter_titles          \n",
    "    for link in total_chapter_links:\n",
    "        driver.get(link)\n",
    "        driver.page_source\n",
    "        try:\n",
    "            chapter_container = driver.find_element(By.CLASS_NAME, 'mt-content-container')\n",
    "            subchapter_text_container = chapter_container.find_elements(By.TAG_NAME,'p') \n",
    "            for subchap in subchapter_text_container:\n",
    "                if subchap.text.strip() != '':\n",
                         chapter_contents.append(subchap.text.strip())\n",
                     else:\n"
                         pass\"
    "        except:\n",
    "            EC, NoSuchElementException, StaleElementReferenceException \n",
    "            \n",
    "    #store the data as JSON file with bookshelves' name as filename\n",
    "    \n",
    "    data = chapter_contents \n",
    "    \n",
    "    filename = bookshelves_name\n",
    "    with open(filename, \"w\") as outfile:\n",
    "            json.dump(data, outfile)\n",
    "    # the function returns the list of book titles and the number of total chapter(main and sub) hyperlinks     \n",
    "    return book_titles,len(total_chapter_links), driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Book: Geochemistry (Lower)',\n",
       "  'Book: Key Elements of Green Chemistry (Lucia)'],\n",
       " 42,\n",
       " 12,\n",
       " 54,\n",
       " 54,\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemlibertexts_book_parser('https://chem.libretexts.org/Bookshelves/Environmental_Chemistry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
